{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7d3f9fd-8e09-4b6d-8046-7442c5bbdf3e",
   "metadata": {},
   "source": [
    "# Job-candidate matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57674400-6b17-4800-8b7b-e783a3649a2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IuG_Lap1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\IuG_Lap1\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e99c3a2-7aae-4d6a-93a4-44ba11bb9a94",
   "metadata": {},
   "source": [
    "##### 1. Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "756751e3-80b8-4fc9-99bd-dc515db8c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df = pd.read_csv(\"cv_records.csv\")\n",
    "job_df = pd.read_csv(\"job_records.csv\")\n",
    "\n",
    "cv_id_to_idx = dict(zip(cv_df[\"cv_id\"], range(len(cv_df))))\n",
    "job_id_to_idx = dict(zip(job_df[\"job_id\"], range(len(job_df))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1364a4ad-5cbe-4f01-88c6-1d5eae92558a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matched pairs: 11520\n"
     ]
    }
   ],
   "source": [
    "# Build all CV-Job posting matched pairs (same ROLE)\n",
    "from collect_cv_job_pairs import collect_cv_job_pairs\n",
    "\n",
    "job_pairs = collect_cv_job_pairs(cv_df, job_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0b3685a-8960-44a7-a74f-a7a40dfcd8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"similarity_matching_output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39e465f-cc2c-4227-8811-9c077383dd8f",
   "metadata": {},
   "source": [
    "## JobBERT-v2\n",
    "\n",
    "https://huggingface.co/TechWolf/JobBERT-v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eba7cf-9b52-4725-907b-eaa5ab256796",
   "metadata": {},
   "source": [
    "##### Load model and encode texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c93ce28c-7225-4f80-92da-6bb87ef4ec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"TechWolf/JobBERT-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f530a5-fe9f-40ac-9f7c-6d2c2339e02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_embeddings_v2 = model.encode(cv_df[\"description\"].tolist(), normalize_embeddings=True)\n",
    "job_embeddings_v2 = model.encode(job_df[\"text\"].tolist(), normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3965db2-6b40-4414-be7c-f363c6621202",
   "metadata": {},
   "source": [
    "##### Compute similarity only for matched pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a45966-4efc-4d2e-9fc7-d4e410e09bf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "for cv_id, job_id in job_pairs:\n",
    "    cv_idx = cv_id_to_idx[cv_id]\n",
    "    job_idx = job_id_to_idx[job_id]\n",
    "\n",
    "    sim = util.cos_sim(\n",
    "        cv_embeddings_v2[cv_idx],\n",
    "        job_embeddings_v2[job_idx]\n",
    "    ).item()\n",
    "\n",
    "    records.append({\n",
    "        \"cv_id\": cv_id,\n",
    "        \"name\": cv_df.loc[cv_idx, \"name\"],\n",
    "        \"gender\": cv_df.loc[cv_idx, \"gender\"],\n",
    "        \"ethnicity\": cv_df.loc[cv_idx, \"ethnicity\"],\n",
    "        \"role\": cv_df.loc[cv_idx, \"role\"],\n",
    "\n",
    "        \"job_id\": job_id,\n",
    "        \"job_role\": job_df.loc[job_idx, \"role\"],\n",
    "        \"job_domain\": job_df.loc[job_idx, \"domain\"] if \"domain\" in job_df.columns else None,\n",
    "        \"job_level\": job_df.loc[job_idx, \"level\"],\n",
    "        \"job_text\": job_df.loc[job_idx, \"text\"],\n",
    "\n",
    "        \"similarity\": sim\n",
    "    })\n",
    "\n",
    "out_df = pd.DataFrame(records)\n",
    "out_path = os.path.join(out_dir, \"cv_job_similarity_jb_v2.csv\")\n",
    "out_df.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Saved → {out_path}\")\n",
    "out_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4491701-b1a1-4a9d-9bb4-6fbefa69a37f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379cdb33-24a4-48a3-8e44-ee752f4a3360",
   "metadata": {},
   "source": [
    "## JobBERT-v3\n",
    "\n",
    "https://huggingface.co/TechWolf/JobBERT-v3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c4f455-ab06-45e9-a111-96a1b0effffb",
   "metadata": {},
   "source": [
    "##### Load model and encode texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3474a110-1ffe-451d-9ff2-561e6310c247",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"TechWolf/JobBERT-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4780c4-f9d8-4fdc-be82-5e3b34daf486",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_embeddings_v3 = model.encode(cv_df[\"description\"].tolist(), normalize_embeddings=True)\n",
    "job_embeddings_v3 = model.encode(job_df[\"text\"].tolist(), normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ca6208-6e9d-471e-bf55-02d7fa240b82",
   "metadata": {},
   "source": [
    "##### Compute similarity only for matched pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535d0897-482b-4433-8246-d18b48d6439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "for cv_id, job_id in job_pairs:\n",
    "    cv_idx = cv_id_to_idx[cv_id]\n",
    "    job_idx = job_id_to_idx[job_id]\n",
    "\n",
    "    sim = util.cos_sim(\n",
    "        cv_embeddings_v3[cv_idx],\n",
    "        job_embeddings_v3[job_idx]\n",
    "    ).item()\n",
    "\n",
    "    records.append({\n",
    "        \"cv_id\": cv_id,\n",
    "        \"name\": cv_df.loc[cv_idx, \"name\"],\n",
    "        \"gender\": cv_df.loc[cv_idx, \"gender\"],\n",
    "        \"ethnicity\": cv_df.loc[cv_idx, \"ethnicity\"],\n",
    "        \"role\": cv_df.loc[cv_idx, \"role\"],\n",
    "\n",
    "        \"job_id\": job_id,\n",
    "        \"job_role\": job_df.loc[job_idx, \"role\"],\n",
    "        \"job_domain\": job_df.loc[job_idx, \"domain\"] if \"domain\" in job_df.columns else None,\n",
    "        \"job_level\": job_df.loc[job_idx, \"level\"],\n",
    "        \"job_text\": job_df.loc[job_idx, \"text\"],\n",
    "\n",
    "        \"similarity\": sim\n",
    "    })\n",
    "\n",
    "out_df = pd.DataFrame(records)\n",
    "out_path = os.path.join(out_dir, \"cv_job_similarity_jb_v3.csv\")\n",
    "out_df.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Saved → {out_path}\")\n",
    "out_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe8b202-d067-482f-9e65-5fab02687dd0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7181906-e083-4cdc-b2cf-244ec7d2377b",
   "metadata": {},
   "source": [
    "## Paraphrase-multilingual-MiniLM-L12 V2 \n",
    "\n",
    "A job matching sentence-transformers model finetuned from **sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2**\n",
    "https://huggingface.co/forestav/job_matching_sentence_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25aecee-c397-4233-932e-41f15433ef98",
   "metadata": {},
   "source": [
    "##### Load model and encode texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34405cc4-6577-4cfd-8de9-ef4d9345368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = SentenceTransformer(\"forestav/job_matching_sentence_transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6c03cc-7e86-4052-a5eb-d21e7dee107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_embeddings_minilm = model_2.encode(cv_df[\"description\"].tolist(), normalize_embeddings=True)\n",
    "job_embeddings_minilm = model_2.encode(job_df[\"text\"].tolist(), normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b866d8c3-c7cc-42ed-b835-62bbfd9473a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "for cv_id, job_id in job_pairs:\n",
    "    cv_idx = cv_id_to_idx[cv_id]\n",
    "    job_idx = job_id_to_idx[job_id]\n",
    "\n",
    "    sim = util.cos_sim(\n",
    "        cv_embeddings_minilm[cv_idx],\n",
    "        job_embeddings_minilm[job_idx]\n",
    "    ).item()\n",
    "\n",
    "    records.append({\n",
    "        \"cv_id\": cv_id,\n",
    "        \"name\": cv_df.loc[cv_idx, \"name\"],\n",
    "        \"gender\": cv_df.loc[cv_idx, \"gender\"],\n",
    "        \"ethnicity\": cv_df.loc[cv_idx, \"ethnicity\"],\n",
    "        \"role\": cv_df.loc[cv_idx, \"role\"],\n",
    "\n",
    "        \"job_id\": job_id,\n",
    "        \"job_role\": job_df.loc[job_idx, \"role\"],\n",
    "        \"job_domain\": job_df.loc[job_idx, \"domain\"] if \"domain\" in job_df.columns else None,\n",
    "        \"job_level\": job_df.loc[job_idx, \"level\"],\n",
    "        \"job_text\": job_df.loc[job_idx, \"text\"],\n",
    "\n",
    "        \"similarity\": sim\n",
    "    })\n",
    "\n",
    "out_df = pd.DataFrame(records)\n",
    "out_path = os.path.join(out_dir, \"cv_job_similarity_minilm_base.csv\")\n",
    "out_df.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Saved → {out_path}\")\n",
    "out_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20c9217-5068-4751-ac25-8513d49f27bf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a900c2a7-89c7-4b4a-822c-3b98b902e34b",
   "metadata": {},
   "source": [
    "## Fairness LoRA \n",
    "\n",
    "Fairness-aware LoRA adapter for resume–job matching built on top of **BAAI/bge-large-en-v1.5** \\\n",
    "https://huggingface.co/renhehuang/fair-resume-job-matcher-lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fa2904-3b68-4359-9f8e-da0d237b721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "BASE = \"BAAI/bge-large-en-v1.5\"\n",
    "ADAPTER = \"renhehuang/fair-resume-job-matcher-lora\"  # HF repo id\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE)\n",
    "base_model = AutoModel.from_pretrained(BASE)\n",
    "\n",
    "# Load LoRA adapter from Hugging Face\n",
    "model_bge = PeftModel.from_pretrained(base_model, ADAPTER)\n",
    "model_bge.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30263b06-865b-431c-ab8c-0604863b73f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_batch(texts, max_length: int = 256):\n",
    "    \"\"\"Encode a batch of texts into L2-normalized embeddings (torch.Tensor).\"\"\"\n",
    "    enc = tokenizer(\n",
    "        texts,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=max_length,\n",
    "    )\n",
    "    enc = {k: v.to(\"cpu\") for k, v in enc.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model_bge(**enc)\n",
    "        hidden = out.last_hidden_state                      # (batch, seq_len, hidden)\n",
    "        emb = hidden.mean(dim=1)                            # simple mean pooling\n",
    "        emb = F.normalize(emb, p=2, dim=1)                  # L2 norm\n",
    "\n",
    "    return emb  # (batch, hidden)\n",
    "\n",
    "def encode_all(texts, batch_size: int = 16, max_length: int = 256):\n",
    "    \"\"\"Encode an iterable of texts to a single (N, d) tensor.\"\"\"\n",
    "    all_embs = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i : i + batch_size]\n",
    "        batch_embs = encode_batch(batch_texts, max_length=max_length)\n",
    "        all_embs.append(batch_embs.cpu())\n",
    "    return torch.cat(all_embs, dim=0)   # (N, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa963ab1-2187-4550-98cb-8fc60c38d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_embeddings_bge = encode_all(cv_df[\"description\"].tolist(), batch_size=16)\n",
    "job_embeddings_bge = encode_all(job_df[\"text\"].tolist(), batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec093f62-80e1-47d5-a538-81b3eb30f809",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "for cv_id, job_id in job_pairs:\n",
    "    cv_idx = cv_id_to_idx[cv_id]\n",
    "    job_idx = job_id_to_idx[job_id]\n",
    "\n",
    "    cv_emb = cv_embeddings_bge[cv_idx]\n",
    "    job_emb = job_embeddings_bge[job_idx]\n",
    "\n",
    "    # embeddings are already normalized → dot product = cosine similarity\n",
    "    sim = torch.dot(cv_emb, job_emb).item()\n",
    "\n",
    "    # if you want the \"probability\" style score they use in the example:\n",
    "    # prob = torch.sigmoid(torch.tensor(sim)).item()\n",
    "\n",
    "    records.append({\n",
    "        \"cv_id\": cv_id,\n",
    "        \"name\": cv_df.loc[cv_idx, \"name\"],\n",
    "        \"gender\": cv_df.loc[cv_idx, \"gender\"],\n",
    "        \"ethnicity\": cv_df.loc[cv_idx, \"ethnicity\"],\n",
    "        \"role\": cv_df.loc[cv_idx, \"role\"],\n",
    "\n",
    "        \"job_id\": job_id,\n",
    "        \"job_role\": job_df.loc[job_idx, \"role\"],\n",
    "        \"job_domain\": job_df.loc[job_idx, \"domain\"] if \"domain\" in job_df.columns else None,\n",
    "        \"job_level\": job_df.loc[job_idx, \"level\"],\n",
    "        \"job_text\": job_df.loc[job_idx, \"text\"],\n",
    "\n",
    "        \"similarity\": sim,\n",
    "        # \"prob\": prob,              # uncomment if you want this column too\n",
    "    })\n",
    "\n",
    "out_df = pd.DataFrame(records)\n",
    "out_path = os.path.join(out_dir, \"cv_job_similarity_fair_lora.csv\")\n",
    "out_df.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Saved → {out_path}\")\n",
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ed9825-0765-41ea-bf3b-1989202d3294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
